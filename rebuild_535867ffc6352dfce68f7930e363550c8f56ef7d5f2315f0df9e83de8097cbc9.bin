#!/usr/bin/env python3
"""
mongo_safe_upload_v2.py: Upload large files in chunks to MongoDB safely.
Usage:
  python3 mongo_safe_upload_v2.py <file_path>

Each file is split into MAX_CHUNK_SIZE byte chunks and stored with metadata:
  - sha: SHA256 of entire file
  - index: chunk index (0-based)
  - total_parts: total number of chunks
  - data: BSON binary chunk
  - timestamp: upload time in ISO format
"""
import sys
import os
import time
import logging
import hashlib
from pathlib import Path
from pymongo import MongoClient, errors
from bson import Binary

# Configuration
HOME_DIR = Path.home()
SOAP_DIR = HOME_DIR / "Soap"
LOG_DIR = SOAP_DIR / "data" / "logs"
LOG_FILE = LOG_DIR / "mongo_upload.log"

MONGO_URI = os.getenv(
    "MONGO_URI",
    "mongodb+srv://lucasreynolds1988:Service2244@ai-sop-dev.nezgetk.mongodb.net/?retryWrites=true&w=majority&appName=ai-sop-dev"
)
MONGO_DB = "rotor"
MONGO_COLL = "fusion_chunks"
MAX_CHUNK_SIZE = 13 * 1024 * 1024  # 13 MB

# Setup logging
def setup_logging():
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    logging.basicConfig(
        filename=str(LOG_FILE),
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s'
    )

logger = logging.getLogger()

def log(msg, level=logging.INFO):
    print(msg)
    logger.log(level, msg)


def compute_file_sha(path: Path) -> str:
    """Compute SHA256 hash of the entire file."""
    hasher = hashlib.sha256()
    with open(path, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b""):
            hasher.update(chunk)
    return hasher.hexdigest()


def upload_file(path: Path):
    if not path.exists() or not path.is_file():
        log(f"‚ùå File not found: {path}", logging.ERROR)
        sys.exit(1)

    # Read file and split into chunks
    file_sha = compute_file_sha(path)
    data = path.read_bytes()
    total_parts = (len(data) + MAX_CHUNK_SIZE - 1) // MAX_CHUNK_SIZE

    log(f"üìÇ Uploading '{path.name}' as {total_parts} chunks (SHA: {file_sha})...")

    client = MongoClient(MONGO_URI)
    coll = client[MONGO_DB][MONGO_COLL]

    for index in range(total_parts):
        start = index * MAX_CHUNK_SIZE
        end = start + MAX_CHUNK_SIZE
        chunk = data[start:end]
        doc = {
            "sha": file_sha,
            "index": index,
            "total_parts": total_parts,
            "data": Binary(chunk),
            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
        }
        try:
            coll.insert_one(doc)
            log(f"‚úÖ Uploaded chunk {index + 1}/{total_parts}")
        except errors.PyMongoError as e:
            log(f"‚ùå Failed uploading chunk {index}: {e}", logging.ERROR)
            sys.exit(1)

    log(f"üéâ Upload complete. File '{path.name}' available in MongoDB (SHA: {file_sha}).")


def main():
    setup_logging()
    if len(sys.argv) != 2:
        print(__doc__)
        sys.exit(1)
    upload_file(Path(sys.argv[1]))

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        log(f"‚ùå Unexpected error: {e}", logging.ERROR)
        sys.exit(1)
